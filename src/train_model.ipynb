{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "This class is used to train the models. It makes all the necessary setup (environment configs, environement setup, hyperparameters setup) for training.\n",
    "Models can be trained through specification of hyperparameters, or through random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import gymnasium as gym\n",
    "from typing import List\n",
    "from environment import MarketEnv\n",
    "import constants\n",
    "import json, glob, os, pickle, datetime\n",
    "from visualizer import Visualizer\n",
    "from util import get_datasets, get_train_validate_test_datasets\n",
    "import os \n",
    "from pytorch_lightning import loggers\n",
    "import ppo\n",
    "from constants import *\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from environment import Config\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "datasets = get_datasets()\n",
    "train_sets, validation_sets, test_sets = get_train_validate_test_datasets(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_configs = Config(\n",
    "    MEAN_RUN_DURATION = 100,\n",
    "    STD_RUN_DURATION = 10,\n",
    "    START_BALANCE = 1000,\n",
    "    MAX_BUY_LIMIT = 10,\n",
    "    CONTINUOUS_MODEL = False,\n",
    "    TRUNCATION_PENALTY = 0,\n",
    "    STOCK_HOLDING_REWARD=0,\n",
    "    RESTING_PENALTY=1,\n",
    "    RESTING_PENALTY_START=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.register(\"MarketEnv-v0\", entry_point=MarketEnv)\n",
    "env = gym.make(\"MarketEnv-v0\", datasets=train_sets, config=env_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'gamma': 0.8277782036668777,\n",
    "    'lam': 0.8425986928387932,\n",
    "    'lr_actor': 0.0002484147755421103, \n",
    "    'lr_critic': 0.001950332927924421, \n",
    "    'max_episode_len': 1000, \n",
    "    'batch_size': 64, \n",
    "    'steps_per_epoch': 2048, \n",
    "    'nb_optim_iters': 16, \n",
    "    'clip_ratio': 0.13837575923666506, \n",
    "    'rec_hidden_size': 128, \n",
    "    'fc_hidden_sizes': [16, 16, 16], \n",
    "    'rec_num_layers': 2, \n",
    "    'rec_nonlinearity': 'tanh', \n",
    "    'fc_nonlinearity': 'tanh', \n",
    "    'rnn_type': 'LSTM', \n",
    "    'dropout': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(env, env_configs, hyperparameters, epochs=100):\n",
    "    # Define the model\n",
    "    model = ppo.PPO(env=env, config=env_configs, **hyperparameters)\n",
    "    LOGDIR = os.path.join(\"..\", \"models\", \"generated\")\n",
    "\n",
    "    # Set up tesnorboard logger\n",
    "    tb_logger = loggers.TensorBoardLogger(LOGDIR)\n",
    "\n",
    "\n",
    "    # Define the checkpoint callback for highest average reward\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='avg_reward',\n",
    "        dirpath=tb_logger.log_dir,\n",
    "        filename='model-{epoch:02d}-{avg_reward:.5f}',\n",
    "        save_top_k=5,\n",
    "        mode='max',\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = Trainer(max_epochs=epochs, accelerator=\"gpu\", logger=tb_logger, callbacks=[checkpoint_callback])\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Python311\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Daniel\\OneDrive - TU Wien\\Uni\\7. Semester\\ADL\\repo\\adl\\models\\generated\\lightning_logs\\version_69 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type             | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | critic | RNNModel         | 203 K  | train\n",
      "1 | actor  | ActorCategorical | 203 K  | train\n",
      "----------------------------------------------------\n",
      "407 K     Trainable params\n",
      "0         Non-trainable params\n",
      "407 K     Total params\n",
      "1.629     Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "c:\\Python311\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:212: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Python311\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01890e5a7f47488f887ba8cbabcf1901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    }
   ],
   "source": [
    "train_model(env, env_configs, hyperparameters, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparameters(gamma: float, lam: float, lr_actor: float, lr_critic: float, clip_ratio: float, rec_hidden_size: int, fc_hidden_sizes: List[int], rec_num_layers: int, rec_nonlinearity: str, fc_nonlinearity: str, rnn_type: str, dropout: float):\n",
    "    return {\n",
    "        'gamma': gamma,\n",
    "        'lam': lam,\n",
    "        'lr_actor': lr_actor,\n",
    "        'lr_critic': lr_critic,\n",
    "        'max_episode_len': 1000,\n",
    "        'batch_size': 64,\n",
    "        'steps_per_epoch': 2048,\n",
    "        'nb_optim_iters': 16,\n",
    "        'clip_ratio': clip_ratio,\n",
    "        'rec_hidden_size': rec_hidden_size,\n",
    "        'fc_hidden_sizes': fc_hidden_sizes,\n",
    "        'rec_num_layers': rec_num_layers,\n",
    "        'rec_nonlinearity': rec_nonlinearity,\n",
    "        'fc_nonlinearity': fc_nonlinearity,\n",
    "        'rnn_type': rnn_type,\n",
    "        'dropout': dropout\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        hyperparameters = get_hyperparameters(\n",
    "            gamma = np.random.uniform(0.7, 0.99),\n",
    "            lam = np.random.uniform(0.7, 0.99),\n",
    "            lr_actor = np.random.uniform(0.0001, 0.001),\n",
    "            lr_critic = np.random.uniform(0.0005, 0.005),\n",
    "            clip_ratio = np.random.uniform(0.1, 0.3),\n",
    "            rec_hidden_size = 2**np.random.randint(4, 9),\n",
    "            fc_hidden_sizes = [2**np.random.randint(4, 9) for _ in range(np.random.randint(1, 4))],\n",
    "            rec_num_layers = np.random.randint(1, 4),\n",
    "            rec_nonlinearity = np.random.choice([\"tanh\", \"relu\"]),\n",
    "            fc_nonlinearity = np.random.choice([\"tanh\", \"relu\", \"sigmoid\"]),\n",
    "            rnn_type = np.random.choice([\"GRU\", \"LSTM\", \"RNN\"]),\n",
    "            dropout = max(0, np.random.uniform(-0.7, 0.7))\n",
    "        )\n",
    "        env_configs = Config(\n",
    "            MEAN_RUN_DURATION = 100,\n",
    "            STD_RUN_DURATION = 10,\n",
    "            START_BALANCE = 1000,\n",
    "            MAX_BUY_LIMIT = 10,\n",
    "            CONTINUOUS_MODEL = np.random.choice([False, True]),\n",
    "            TRUNCATION_PENALTY = np.random.choice([0, 0.1, 0.5, 1, 5, 10], p=[0.5, 0.1, 0.1, 0.1, 0.1, 0.1]),\n",
    "            STOCK_HOLDING_REWARD=np.random.choice([0, 0.1, 0.5, 1, 5, 10], p=[0.1, 0.1, 0.1, 0.5, 0.1, 0.1])\n",
    "        )\n",
    "        env = gym.make(\"MarketEnv-v0\", datasets=train_sets, config=env_configs)\n",
    "        train_model(env, env_configs, hyperparameters)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR WITH\", hyperparameters, env_configs)\n",
    "        print(e)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Training of Selected Models\n",
    "\n",
    "The best selected models for further training were versions 10, 40, 41 and 17. From each model, the hyperparameters are extracted and a new model is trained with 1000 instead of 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 5 most promising models\n",
    "selected_models = [\"10\", \"40\", \"41\", \"17\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hyperparameters(model):\n",
    "    env_configs = model.config\n",
    "\n",
    "    hyperparameters = {\n",
    "        'gamma': model.gamma,\n",
    "        'lam': model.lam,\n",
    "        'lr_actor': model.lr_actor, \n",
    "        'lr_critic': model.lr_critic, \n",
    "        'max_episode_len': model.max_episode_len, \n",
    "        'batch_size': model.batch_size, \n",
    "        'steps_per_epoch': model.steps_per_epoch, \n",
    "        'nb_optim_iters': model.nb_optim_iters, \n",
    "        'clip_ratio': model.clip_ratio, \n",
    "        'rec_hidden_size': model.rec_hidden_size, \n",
    "        'fc_hidden_sizes': model.fc_hidden_sizes, \n",
    "        'rec_num_layers': model.rec_num_layers, \n",
    "        'rec_nonlinearity': model.rec_nonlinearity, \n",
    "        'fc_nonlinearity': model.fc_nonlinearity,\n",
    "        'rnn_type': model.rnn_type, \n",
    "        'dropout': model.dropout\n",
    "    }\n",
    "    return env_configs, hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(model_version):\n",
    "    print(os.path.join(MODEL_PATH, \"generated\", \"lightning_logs\", f\"version_{model_version}\", \"*.ckpt\"))\n",
    "    return glob.glob(os.path.join(MODEL_PATH, \"generated\", \"lightning_logs\", f\"version_{model_version}\", \"*.ckpt\"))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_version in selected_models:\n",
    "    path = get_model_path(model_version)\n",
    "    model = ppo.PPO.load_from_checkpoint(path)\n",
    "    config, hyperparameters = extract_hyperparameters(model)\n",
    "    config.TRUNCATION_PENALTY = 10\n",
    "    config.STOCK_HOLDING_REWARD = 1\n",
    "    env = gym.make(\"MarketEnv-v0\", datasets=train_sets, config=config)\n",
    "    train_model(env, config, hyperparameters, epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
