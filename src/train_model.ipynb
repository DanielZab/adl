{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import gymnasium as gym\n",
    "from typing import List\n",
    "from environment import MarketEnv\n",
    "import constants\n",
    "import json, glob, os, pickle, datetime\n",
    "from visualizer import Visualizer\n",
    "from util import get_datasets, get_train_validate_test_datasets\n",
    "import os \n",
    "from pytorch_lightning import loggers\n",
    "import ppo\n",
    "from constants import *\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from environment import Config\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "datasets = get_datasets()\n",
    "train_sets, validation_sets, test_sets = get_train_validate_test_datasets(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_configs = Config(\n",
    "    MEAN_RUN_DURATION = 100,\n",
    "    STD_RUN_DURATION = 10,\n",
    "    START_BALANCE = 1000,\n",
    "    MAX_BUY_LIMIT = 10,\n",
    "    CONTINUOUS_MODEL = False,\n",
    "    TRUNCATION_PENALTY = 0,\n",
    "    STOCK_HOLDING_REWARD=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:642: UserWarning: \u001b[33mWARN: Overriding environment MarketEnv-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "gym.register(\"MarketEnv-v0\", entry_point=MarketEnv)\n",
    "env = gym.make(\"MarketEnv-v0\", datasets=train_sets, config=env_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'gamma': 0.8277782036668777,\n",
    "    'lam': 0.8425986928387932,\n",
    "    'lr_actor': 0.0002484147755421103, \n",
    "    'lr_critic': 0.001950332927924421, \n",
    "    'max_episode_len': 1000, \n",
    "    'batch_size': 64, \n",
    "    'steps_per_epoch': 2048, \n",
    "    'nb_optim_iters': 16, \n",
    "    'clip_ratio': 0.13837575923666506, \n",
    "    'rec_hidden_size': 128, \n",
    "    'fc_hidden_sizes': [16, 16, 16], \n",
    "    'rec_num_layers': 1, \n",
    "    'rec_nonlinearity': 'tanh', \n",
    "    'fc_nonlinearity': 'relu', \n",
    "    'rnn_type': 'GRU', \n",
    "    'dropout': 0.01019550484085563\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(env, env_configs, hyperparameters, epochs=100):\n",
    "    # Define the model\n",
    "    model = ppo.PPO(env=env, config=env_configs, **hyperparameters)\n",
    "    LOGDIR = os.path.join(\"..\", \"models\", \"generated\")\n",
    "\n",
    "    # Set up tesnorboard logger\n",
    "    tb_logger = loggers.TensorBoardLogger(LOGDIR)\n",
    "\n",
    "\n",
    "    # Define the checkpoint callback for highest average reward\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='avg_reward',\n",
    "        dirpath=tb_logger.log_dir,\n",
    "        filename='model-{epoch:02d}-{avg_reward:.5f}',\n",
    "        save_top_k=5,\n",
    "        mode='max',\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = Trainer(max_epochs=epochs, accelerator=\"gpu\", logger=tb_logger, callbacks=[checkpoint_callback])\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(env, env_configs, hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparameters(gamma: float, lam: float, lr_actor: float, lr_critic: float, clip_ratio: float, rec_hidden_size: int, fc_hidden_sizes: List[int], rec_num_layers: int, rec_nonlinearity: str, fc_nonlinearity: str, rnn_type: str, dropout: float):\n",
    "    return {\n",
    "        'gamma': gamma,\n",
    "        'lam': lam,\n",
    "        'lr_actor': lr_actor,\n",
    "        'lr_critic': lr_critic,\n",
    "        'max_episode_len': 1000,\n",
    "        'batch_size': 64,\n",
    "        'steps_per_epoch': 2048,\n",
    "        'nb_optim_iters': 16,\n",
    "        'clip_ratio': clip_ratio,\n",
    "        'rec_hidden_size': rec_hidden_size,\n",
    "        'fc_hidden_sizes': fc_hidden_sizes,\n",
    "        'rec_num_layers': rec_num_layers,\n",
    "        'rec_nonlinearity': rec_nonlinearity,\n",
    "        'fc_nonlinearity': fc_nonlinearity,\n",
    "        'rnn_type': rnn_type,\n",
    "        'dropout': dropout\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        hyperparameters = get_hyperparameters(\n",
    "            gamma = np.random.uniform(0.7, 0.99),\n",
    "            lam = np.random.uniform(0.7, 0.99),\n",
    "            lr_actor = np.random.uniform(0.0001, 0.001),\n",
    "            lr_critic = np.random.uniform(0.0005, 0.005),\n",
    "            clip_ratio = np.random.uniform(0.1, 0.3),\n",
    "            rec_hidden_size = 2**np.random.randint(4, 9),\n",
    "            fc_hidden_sizes = [2**np.random.randint(4, 9) for _ in range(np.random.randint(1, 4))],\n",
    "            rec_num_layers = np.random.randint(1, 4),\n",
    "            rec_nonlinearity = np.random.choice([\"tanh\", \"relu\"]),\n",
    "            fc_nonlinearity = np.random.choice([\"tanh\", \"relu\", \"sigmoid\"]),\n",
    "            rnn_type = np.random.choice([\"GRU\", \"LSTM\", \"RNN\"]),\n",
    "            dropout = max(0, np.random.uniform(-0.7, 0.7))\n",
    "        )\n",
    "        env_configs = Config(\n",
    "            MEAN_RUN_DURATION = 100,\n",
    "            STD_RUN_DURATION = 10,\n",
    "            START_BALANCE = 1000,\n",
    "            MAX_BUY_LIMIT = 10,\n",
    "            CONTINUOUS_MODEL = np.random.choice([False, False]),\n",
    "            TRUNCATION_PENALTY = np.random.choice([0, 0.1, 0.5, 1, 5, 10], p=[0.5, 0.1, 0.1, 0.1, 0.1, 0.1]),\n",
    "            STOCK_HOLDING_REWARD=np.random.choice([0, 0.1, 0.5, 1, 5, 10], p=[0.1, 0.1, 0.1, 0.5, 0.1, 0.1])\n",
    "        )\n",
    "        env = gym.make(\"MarketEnv-v0\", datasets=train_sets, config=env_configs)\n",
    "        train_model(env, env_configs, hyperparameters)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR WITH\", hyperparameters, env_configs)\n",
    "        print(e)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Training of Selected Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 5 most promising models\n",
    "selected_models = [\"10\", \"40\", \"41\", \"17\", \"49\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hyperparameters(model):\n",
    "    env_configs = model.config\n",
    "\n",
    "    hyperparameters = {\n",
    "        'gamma': model.gamma,\n",
    "        'lam': model.lam,\n",
    "        'lr_actor': model.lr_actor, \n",
    "        'lr_critic': model.lr_critic, \n",
    "        'max_episode_len': model.max_episode_len, \n",
    "        'batch_size': model.batch_size, \n",
    "        'steps_per_epoch': model.steps_per_epoch, \n",
    "        'nb_optim_iters': model.nb_optim_iters, \n",
    "        'clip_ratio': model.clip_ratio, \n",
    "        'rec_hidden_size': model.rec_hidden_size, \n",
    "        'fc_hidden_sizes': model.fc_hidden_sizes, \n",
    "        'rec_num_layers': model.rec_num_layers, \n",
    "        'rec_nonlinearity': model.rec_nonlinearity, \n",
    "        'fc_nonlinearity': model.fc_nonlinearity,\n",
    "        'rnn_type': model.rnn_type, \n",
    "        'dropout': model.dropout\n",
    "    }\n",
    "    return env_configs, hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(model_version):\n",
    "    print(os.path.join(MODEL_PATH, \"generated\", \"lightning_logs\", f\"version_{model_version}\", \"*.ckpt\"))\n",
    "    return glob.glob(os.path.join(MODEL_PATH, \"generated\", \"lightning_logs\", f\"version_{model_version}\", \"*.ckpt\"))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\models\\generated\\lightning_logs\\version_10\\*.ckpt\n",
      "..\\models\\generated\\lightning_logs\\version_10\\model-epoch=98-avg_reward=0.01406.ckpt\n",
      "Config(MEAN_RUN_DURATION=100, STD_RUN_DURATION=10, START_BALANCE=1000, MAX_BUY_LIMIT=10, CONTINUOUS_MODEL=False, TRUNCATION_PENALTY=1.0, STOCK_HOLDING_REWARD=0.0) {'gamma': 0.9534776377720052, 'lam': 0.9603592857900016, 'lr_actor': 0.0006038080219594837, 'lr_critic': 0.00472011033911705, 'max_episode_len': 1000, 'batch_size': 64, 'steps_per_epoch': 2048, 'nb_optim_iters': 16, 'clip_ratio': 0.12494504548933082, 'rec_hidden_size': 128, 'fc_hidden_sizes': [64, 256], 'rec_num_layers': 3, 'rec_nonlinearity': 'relu', 'fc_nonlinearity': 'sigmoid', 'rnn_type': 'LSTM', 'dropout': 0.16262403909846335}\n",
      "..\\models\\generated\\lightning_logs\\version_40\\*.ckpt\n",
      "..\\models\\generated\\lightning_logs\\version_40\\model-epoch=97-avg_reward=0.97639.ckpt\n",
      "Config(MEAN_RUN_DURATION=100, STD_RUN_DURATION=10, START_BALANCE=1000, MAX_BUY_LIMIT=10, CONTINUOUS_MODEL=False, TRUNCATION_PENALTY=5.0, STOCK_HOLDING_REWARD=1.0) {'gamma': 0.8986632518988714, 'lam': 0.9694094985092709, 'lr_actor': 0.0005973036152424001, 'lr_critic': 0.0013143268713700946, 'max_episode_len': 1000, 'batch_size': 64, 'steps_per_epoch': 2048, 'nb_optim_iters': 16, 'clip_ratio': 0.28707341074557935, 'rec_hidden_size': 64, 'fc_hidden_sizes': [64, 32], 'rec_num_layers': 3, 'rec_nonlinearity': 'relu', 'fc_nonlinearity': 'tanh', 'rnn_type': 'LSTM', 'dropout': 0}\n",
      "..\\models\\generated\\lightning_logs\\version_41\\*.ckpt\n",
      "..\\models\\generated\\lightning_logs\\version_41\\model-epoch=62-avg_reward=0.58861.ckpt\n",
      "Config(MEAN_RUN_DURATION=100, STD_RUN_DURATION=10, START_BALANCE=1000, MAX_BUY_LIMIT=10, CONTINUOUS_MODEL=False, TRUNCATION_PENALTY=0.1, STOCK_HOLDING_REWARD=0.1) {'gamma': 0.9475296690829087, 'lam': 0.9372258916984196, 'lr_actor': 0.00045238894788263216, 'lr_critic': 0.0039505138972926734, 'max_episode_len': 1000, 'batch_size': 64, 'steps_per_epoch': 2048, 'nb_optim_iters': 16, 'clip_ratio': 0.13824079208242132, 'rec_hidden_size': 32, 'fc_hidden_sizes': [256], 'rec_num_layers': 2, 'rec_nonlinearity': 'relu', 'fc_nonlinearity': 'sigmoid', 'rnn_type': 'RNN', 'dropout': 0}\n",
      "..\\models\\generated\\lightning_logs\\version_17\\*.ckpt\n",
      "..\\models\\generated\\lightning_logs\\version_17\\model-epoch=59-avg_reward=1.00000.ckpt\n",
      "Config(MEAN_RUN_DURATION=100, STD_RUN_DURATION=10, START_BALANCE=1000, MAX_BUY_LIMIT=10, CONTINUOUS_MODEL=False, TRUNCATION_PENALTY=0.1, STOCK_HOLDING_REWARD=10.0) {'gamma': 0.9081213671031185, 'lam': 0.7058482834739124, 'lr_actor': 0.000439305428831033, 'lr_critic': 0.0037360651433220493, 'max_episode_len': 1000, 'batch_size': 64, 'steps_per_epoch': 2048, 'nb_optim_iters': 16, 'clip_ratio': 0.11350448796825185, 'rec_hidden_size': 64, 'fc_hidden_sizes': [32, 128, 64], 'rec_num_layers': 1, 'rec_nonlinearity': 'tanh', 'fc_nonlinearity': 'relu', 'rnn_type': 'LSTM', 'dropout': 0}\n",
      "..\\models\\generated\\lightning_logs\\version_49\\*.ckpt\n",
      "..\\models\\generated\\lightning_logs\\version_49\\model-epoch=96-avg_reward=0.57934.ckpt\n",
      "Config(MEAN_RUN_DURATION=100, STD_RUN_DURATION=10, START_BALANCE=1000, MAX_BUY_LIMIT=10, CONTINUOUS_MODEL=False, TRUNCATION_PENALTY=0.0, STOCK_HOLDING_REWARD=0.1) {'gamma': 0.8674457227885325, 'lam': 0.9605580286343264, 'lr_actor': 0.0009127378271320448, 'lr_critic': 0.003030006173165448, 'max_episode_len': 1000, 'batch_size': 64, 'steps_per_epoch': 2048, 'nb_optim_iters': 16, 'clip_ratio': 0.16342010848904165, 'rec_hidden_size': 64, 'fc_hidden_sizes': [128, 16], 'rec_num_layers': 2, 'rec_nonlinearity': 'relu', 'fc_nonlinearity': 'sigmoid', 'rnn_type': 'RNN', 'dropout': 0.02438640666454217}\n"
     ]
    }
   ],
   "source": [
    "for model_version in selected_models:\n",
    "    path = get_model_path(model_version)\n",
    "    model = ppo.PPO.load_from_checkpoint(path)\n",
    "    config, hyperparameters = extract_hyperparameters(model)\n",
    "    config.TRUNCATION_PENALTY = 10\n",
    "    config.STOCK_HOLDING_REWARD = 1\n",
    "    env = gym.make(\"MarketEnv-v0\", datasets=train_sets, config=config)\n",
    "    train_model(env, config, hyperparameters, epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
